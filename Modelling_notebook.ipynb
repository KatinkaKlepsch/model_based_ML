{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc191726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "#Load packages\n",
    "import numpy as np\n",
    "import pandas as pd   # We import Pandas!\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import torch\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# Data sources:\n",
    "# https://data.mendeley.com/datasets/b5r4yztghx/2\n",
    "\n",
    "# project (Rico)\n",
    "# https://www.sciencedirect.com/science/article/abs/pii/S1877584518301175\n",
    "# https://mc-stan.org/users/documentation/case-studies/icar_stan.html\n",
    "\n",
    "\n",
    "# Artikel\n",
    "# https://www1.nyc.gov/assets/doh/downloads/pdf/epi/databrief86.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perfomrnace metrics\n",
    "Following metrics will be used to evaluate the performance of the models and how good they are at predicting the number of accidents amongst the youth populations.\n",
    "* Accuracy..\n",
    "* \n",
    "\n",
    "### Data\n",
    "* Standardised?\n",
    "\n",
    "\n",
    "#### Feature selection\n",
    "we have many features, the model can very well be dirven by bias as many features has a high correlation..???\n",
    "\n",
    "### Models\n",
    "\n",
    "* baseline model\n",
    " >The baseline is based on the assumption that there is a linear relation between the events. The baseline is implemented using a linear regression on the data and will serve as a benchmark when evaluating the performance of the other models.\n",
    "\n",
    "* Bayesian hierachial model\n",
    "> From the maps and distributions from the exploratory analysis it seemed as some locations are more prone to accidents. Using an hierachical model it is investigeated if we can naturally cluster data into some groups and thereby be able to predict more accurately. Bayesian Hierachical models are able to produce robust models with clustered data. As the data seemed to cluster dependent on county, this is investigated. \n",
    "\n",
    "**copied** https://towardsdatascience.com/introduction-to-hierarchical-modeling-a5c7b2ebb1ca\n",
    "\n",
    " this method, parameters are nested within one another at different levels of groups. Roughly, it gives us the weighted average of the unpooled and pooled model estimates. Hierarchical modeling is one of the most powerful, yet simple, techniques in Bayesian inference and possibly in statistical modeling.\n",
    "\n",
    "\n",
    "* Models with a non linear assumption\n",
    "    > Extension of the hierachical model to include non linearity\n",
    "\n",
    "\n",
    "\n",
    "* ???\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to performance metrics (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "* split function\n",
    "* data standardisation function\n",
    "* \n",
    "\n",
    "Cosinder moving to another file location (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get input, output and groups by counties.\n",
    " def split_data(df, attributes,impute = False):\n",
    "    X = df[attributes]\n",
    "    \n",
    "    # Handling missing data - impute data based on the median.\n",
    "    if impute:\n",
    "        X = X.fillna(X.median()).values\n",
    "    \n",
    "    # Target variable\n",
    "    y = df[\"ped_injury_5to18\"].values\n",
    "    \n",
    "    \n",
    "    # split data into test and train\n",
    "    ...\n",
    "    # split into train test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    \n",
    "    return (X_train, X_test), (y_train, y_test), attributes\n",
    "\n",
    "\n",
    "\n",
    "def standardization(X):\n",
    "    return (X - X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1403, 42) (692, 42) (1403,) (692,)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df_all = pd.read_csv(\"data/data_merged.csv\")  \n",
    "\n",
    "\n",
    "# split target variables and variables into training and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attriutes that are stirng - either make the dummy variables or remove them\n",
    "string_att = list(df_all.columns[df_all.dtypes == object])\n",
    "# df_all.loc[:, df_all.dtypes == object]\n",
    "nominal = ['census_tract']\n",
    "removed_attributes = nominal+string_att\n",
    "df_all = df_all[df_all.columns[~df_all.columns.isin(removed_attributes)]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1403, 39) (692, 39) (1403,) (692,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_test), (y_train, y_test), attributes = split_data(df_all, df_all.columns,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise data\n",
    "#X_train_mean = X_train.mean(axis=0)\n",
    "#X_train_std = X_train.std(axis=0)\n",
    "#X_train = (X_train - X_train_mean) / X_train_std\n",
    "#X_test = (X_test - X_train_mean) / X_train_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std = standardization(X_train)\n",
    "X_test_std = standardization(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBS: TILFØJ! - Burde man kigge på balancen af splittet i forhold til counties evt?**\n",
    "* imbalanced datasæt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model\n",
    "\n",
    "An Ordinary least square regression is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make linear regression model\n",
    "l_reg = linear_model.LinearRegression(fit_intercept=False)\n",
    "l_reg.fit(X_train_std, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.39654288e+00 -7.54900087e-12 -5.16044133e-12  3.07383586e-12\n",
      "  3.67912064e-13 -3.25291149e-12  5.54320640e-12  1.16569085e-12\n",
      "  9.19928282e-12  3.43772967e-13 -1.16980530e-12  1.70443281e-12\n",
      "  3.34886942e-13  5.31048337e-13 -4.03301822e-12 -4.60308890e-12\n",
      " -8.67836920e-13  6.56955037e-12 -1.04842187e-12  3.57330507e-12\n",
      " -3.16680399e-12 -3.42681010e-09 -2.24569213e-09 -1.16210233e-09\n",
      " -8.69864465e-10 -1.03983884e-09 -2.61153361e-09 -6.27440989e-10\n",
      " -2.52403278e-09 -1.42999301e-09 -4.07923336e-10 -4.99418366e-10\n",
      "  7.08615978e-13 -7.15279297e-12  3.63958764e-09  3.83923745e-09\n",
      "  1.83883384e-09  2.16286671e-10 -1.42090732e-13]\n"
     ]
    }
   ],
   "source": [
    "preds_lr = l_reg.predict(X_test_std)\n",
    "print(l_reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 predictions: [-7.05426509  2.7225253  -0.21051182 -5.09890701 10.54395761]\n",
      "first 5 true values: [ 1 11  8  3 19]\n",
      "Baseline MSE: 67.51996465192855\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions for test set\n",
    "yhat_l_reg = l_reg.predict(X_test_std)\n",
    "print(\"first 5 predictions:\", yhat_l_reg[:5])\n",
    "print(\"first 5 true values:\", y_test[:5])\n",
    "\n",
    "# Evaluate prediction accuracy\n",
    "print(\"Baseline MSE:\", sum((yhat_l_reg - y_test)**2)/len(yhat_l_reg))\n",
    "\n",
    "# Vi får ikke det samme some de andre - måske noget gal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierachical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierachical model with a non linear assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87186a436f2567f36eabb9c190ca2d08069d3d8da5be0ad9e4dc543665bcc6fa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
